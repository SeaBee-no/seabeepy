{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff5904-aad4-4a24-aa89-5fb262857938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import yaml\n",
    "from seabeepy.config import SETTINGS\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import seabeepy as sb\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842e552-4e07-4ad9-b302-476562907463",
   "metadata": {},
   "source": [
    "# Refactor `config.seabee.yaml` for niva-tidy missions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2beb8-36b0-4122-9c5a-23306962c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to MinIO\n",
    "minio_client = sb.storage.minio_login(\n",
    "    user=SETTINGS.MINIO_ACCESS_ID, password=SETTINGS.MINIO_SECRET_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1235ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent directories containing flight folders to process\n",
    "base_dirs = [\n",
    "    Path(r\"/home/notebook/shared-seabee-ns9879k/niva-tidy/2022\"),\n",
    "    Path(r\"/home/notebook/shared-seabee-ns9879k/niva-tidy/2023\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c0e27-0563-492e-b1bc-bc85aeb556c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrum_type(spec: str):\n",
    "    if spec is None:\n",
    "        return None\n",
    "    if spec.lower() in [\"rgb\", \"msi\", \"hsi\"]:\n",
    "        return spec.lower()\n",
    "    if spec.lower() == \"ms\":\n",
    "        return \"msi\"\n",
    "\n",
    "\n",
    "def template_config() -> dict:\n",
    "    return dict(\n",
    "        grouping=None,\n",
    "        area=None,\n",
    "        datetime=None,\n",
    "        spectrum_type=None,\n",
    "        elevation=None,\n",
    "        project=None,\n",
    "        nfiles=None,\n",
    "        organisation=None,\n",
    "        creator_name=None,\n",
    "        theme=\"habitat\",\n",
    "        mosaic=False,\n",
    "        publish=True,\n",
    "        classify=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def niva_name_to_config(name: str):\n",
    "\n",
    "    parts = name.split(\"_\")\n",
    "\n",
    "    if len(parts) == 7:\n",
    "        org, date, group, area, spect, elev, _ = parts\n",
    "    elif len(parts) == 6:\n",
    "        org, date, group, area, spect, elev = parts\n",
    "    elif len(parts) == 5:\n",
    "        org, date, group, area, spect = parts\n",
    "        elev = None\n",
    "    elif len(parts) == 4:\n",
    "        org, date, group, area = parts\n",
    "        spect = None\n",
    "        elev = None\n",
    "    return dict(\n",
    "        grouping=group,\n",
    "        area=area,\n",
    "        datetime=date,\n",
    "        spectrum_type=get_spectrum_type(spect),\n",
    "        organisation=org,\n",
    "        elevation=int(elev) if elev is not None and elev.isnumeric() else elev,\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_config(dir_path: Path):\n",
    "    conf = {}\n",
    "    config_path = dir_path / \"config.seabee.yaml\"\n",
    "    if config_path.exists():\n",
    "        with open(config_path, \"r\") as f:\n",
    "            conf = yaml.safe_load(f)\n",
    "    return conf\n",
    "\n",
    "\n",
    "def write_new_config(path: Path, data):\n",
    "    with open(path, \"w\") as yaml_file:\n",
    "        yaml.dump(data, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "\n",
    "def merge_conf(folder_config: dict, existing_config: dict) -> dict:\n",
    "    \"\"\"Merge the folder_config with the existing_config\n",
    "\n",
    "    Use various rules some times use folder name is best, other times the config\n",
    "    \"\"\"\n",
    "\n",
    "    new_config = template_config()\n",
    "    for key, val in folder_config.items():\n",
    "        new_config[key] = val\n",
    "    for key in [\"creator_name\", \"project\", \"mosaic\", \"publish\", \"theme\", \"area\", \"spectrum_type\"]:\n",
    "        if key in existing_config:\n",
    "            if key == \"creator_name\" and \"_\" in existing_config[key]:\n",
    "                new_config[key] = \" \".join(existing_config[key].split(\"_\"))\n",
    "            else:\n",
    "                new_config[key] = existing_config[key]\n",
    "    \n",
    "    # If file config is placeholder switch back to config based on folder name\n",
    "    if new_config[\"area\"].lower() in [\"site\", \"oslo\"]:\n",
    "        new_config[\"area\"] = folder_config[\"area\"]\n",
    "\n",
    "    if new_config[\"spectrum_type\"] is None:\n",
    "        new_config[\"spectrum_type\"] = existing_config[\"spectrum_type\"]\n",
    "    new_config[\"folder_grouping\"] = folder_config[\"grouping\"]\n",
    "    return apply_rules(new_config)\n",
    "\n",
    "\n",
    "def apply_rules(config: dict, folder_name=\"\"):\n",
    "    # msi -> ms + lower\n",
    "    config[\"spectrum_type\"] = get_spectrum_type(config[\"spectrum_type\"])\n",
    "    if not isinstance(config[\"elevation\"], int):\n",
    "        config[\"elevation\"] = None\n",
    "    # No underscore in attributes, this destroys the layer name\n",
    "    if \"_\" in config[\"area\"]:\n",
    "        config[\"area\"] = config[\"area\"].replace(\"_\", \"-\")\n",
    "    \n",
    "    if \"oldberg\" in config[\"area\"]:\n",
    "        config[\"area\"] = config[\"area\"].replace(\"oldberg\", \"olberg\")\n",
    "    \n",
    "    if config[\"area\"].startswith(\"larvik-\"):\n",
    "        config[\"area\"] = config[\"area\"].split(\"-\", 1)[-1]\n",
    "\n",
    "    if config[\"area\"].startswith(\"runde-\"):\n",
    "        config[\"area\"] = config[\"area\"].split(\"-\", 1)[-1]\n",
    "\n",
    "    if config[\"project\"] is None:\n",
    "        # Around three missions with missing project, use seabee\n",
    "        config[\"project\"] = \"seabee\"\n",
    "    \n",
    "    config[\"project\"] = config[\"project\"].lower()\n",
    "    \n",
    "    if config[\"project\"] in [\"runderunderunderunde\", \"srunde\"]:\n",
    "        config[\"project\"] = \"runde\"\n",
    "    \n",
    "    if config[\"area\"] == \"runde\":\n",
    "        config[\"project\"] = \"runde\"\n",
    "\n",
    "    if config[\"area\"].startswith(\"runde-\"):\n",
    "        config[\"area\"] = config[\"area\"].split(\"-\", 1)[-1]\n",
    "    \n",
    "    if folder_name: \n",
    "        if config[\"area\"] == \"olberg\":\n",
    "            config[\"area\"] = niva_name_to_config(folder_name)[\"area\"]\n",
    "        if \"_msi_\" in folder_name:\n",
    "             config[\"spectrum_type\"]=\"msi\"\n",
    "        elif \"_hsi_\" in folder_name:\n",
    "            config[\"spectrum_type\"]=\"hsi\"\n",
    "        elif \"_rgb_\" in folder_name:\n",
    "            config[\"spectrum_type\"]=\"rgb\" \n",
    "    # Check folder grouping\n",
    "    if config[\"project\"] in [\"seabee\"]:\n",
    "        # try to use naming from folder name for project\n",
    "        config[\"project\"] = config[\"folder_grouping\"]\n",
    "    \n",
    "    if config[\"project\"] in [\"oslo\", \"io\"]:\n",
    "        config[\"project\"] = \"io23\"\n",
    "\n",
    "    if config[\"project\"] == \"io23\" and \"oslo\" not in config[\"area\"]:\n",
    "        config[\"area\"] = \"oslo-\" + config[\"area\"]\n",
    "\n",
    "    if config[\"project\"] == \"plastinoland\":\n",
    "        config[\"project\"] = \"plastnoland\"\n",
    "\n",
    "    if config[\"project\"] == \"larvik\":\n",
    "        # spresial rule for larvik ending up as project?\n",
    "        config[\"project\"] = \"zosmap\"\n",
    "        \n",
    "\n",
    "    if config[\"organisation\"] in [\"spectorfly\"]:\n",
    "        config[\"organisation\"] = \"spectrofly\"\n",
    "    \n",
    "    if \"stege-nor\" in config[\"area\"].lower():\n",
    "        config[\"grouping\"] = f\"{config['organisation'].lower()}\"\n",
    "        config[\"area\"] = config[\"area\"].lower()\n",
    "        if config[\"area\"].lower() == \"stege-nor\" :\n",
    "            config[\"area\"] = \"stege-nor-full\"\n",
    "    elif folder_name.endswith(\"_odm\"):\n",
    "        config[\"grouping\"] = f\"{config['organisation'].lower()}-{config['project'].lower()}-odm-test\"\n",
    "    else:\n",
    "        config[\"grouping\"] = f\"{config['organisation'].lower()}-{config['project'].lower()}\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def to_seabee_config(df: pd.DataFrame, tmp_dir):\n",
    "    \"\"\"Try to convert the dataframe to seabee config files\n",
    "\n",
    "    Try to save df to seabee config files and resturn a new dataframe with the results\n",
    "    this way we can play a bit with various changes and resulting layer name. The config files\n",
    "    are saved in tmp_dir.\n",
    "    \"\"\"\n",
    "    mission_dict = dict(folder_name=[], layer_name=[], valid=[], dir_path=[])\n",
    "    keys = template_config().keys()\n",
    "    mission_dict.update({k: [] for k in keys})\n",
    "    mission_dict[\"folder_grouping\"] = []\n",
    "    mission_dict[\"old_layer_name\"] = []\n",
    "    mission_dict[\"dir_path\"] = []\n",
    "    for _, data in df.iterrows():\n",
    "        mission_name = data[\"folder_name\"]\n",
    "        config = apply_rules(data[list(keys) + [\"folder_grouping\"]].to_dict(), mission_name)\n",
    "        clean_config = {k: config[k] for k in keys if config[k] is not None}\n",
    "        nfiles = len(sb.ortho.list_images(data.dir_path / \"images\", verbose=False))\n",
    "        mission_dict[\"folder_name\"].append(mission_name)\n",
    "        try:\n",
    "            sb.ortho.CONFIG_SCHEMA.validate({**clean_config, \"nfiles\": 1})\n",
    "            write_new_config(tmp_dir / \"config.seabee.yaml\", clean_config)\n",
    "            layer_name = sb.ortho.get_layer_name(tmp_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {mission_name}: {e}\")\n",
    "            config[\"nfiles\"] = nfiles\n",
    "            mission_dict[\"layer_name\"].append(\"error\")\n",
    "            mission_dict[\"valid\"].append(False)\n",
    "        else:\n",
    "            config[\"nfiles\"] = nfiles\n",
    "            mission_dict[\"layer_name\"].append(layer_name)\n",
    "            mission_dict[\"valid\"].append(True)\n",
    "            tmp_file = tmp_dir / f\"{mission_name}.yaml\"\n",
    "            write_new_config(tmp_file, config)\n",
    "\n",
    "        for k, v in config.items():\n",
    "            mission_dict[k].append(v)\n",
    "        mission_dict[\"dir_path\"].append(data.dir_path)\n",
    "        mission_dict[\"old_layer_name\"].append(data.old_layer_name)\n",
    "\n",
    "    return pd.DataFrame(mission_dict).astype(dict(elevation=\"Int16\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef53250",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [\n",
    "    p\n",
    "    for p in base_dirs\n",
    "    for p in p.iterdir()\n",
    "    if p.is_dir() and (p / \"config.seabee.yaml\").exists()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = Path(\"./tmp\")\n",
    "tmp_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c0b7f2-6878-420a-af09-5e6a17a6f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_dict = dict(folder_name=[], dir_path=[])\n",
    "mission_dict.update({k: [] for k in template_config().keys()})\n",
    "mission_dict[\"folder_grouping\"] = []\n",
    "mission_dict[\"old_layer_name\"] = []\n",
    "for dir_path in dir_list:\n",
    "    # Update config\n",
    "    mission_name = os.path.split(dir_path)[-1]\n",
    "    existing_conf = parse_config(dir_path)\n",
    "    write_new_config(tmp_dir / \"config.seabee.yaml\", existing_conf)\n",
    "    mission_dict[\"old_layer_name\"].append(sb.ortho.get_layer_name(tmp_dir))\n",
    "    folder_conf = niva_name_to_config(mission_name)\n",
    "    new_conf = merge_conf(folder_conf, existing_conf)\n",
    "    mission_dict[\"folder_name\"].append(mission_name)\n",
    "    nfiles = len(sb.ortho.list_images(dir_path / \"images\", verbose=False))\n",
    "    new_conf[\"nfiles\"] = nfiles\n",
    "    for k, v in new_conf.items():\n",
    "        mission_dict[k].append(v)\n",
    "    mission_dict[\"dir_path\"].append(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ce03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mission_dict).astype(dict(elevation=\"Int16\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedf5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = to_seabee_config(df, tmp_dir)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e584f-6d85-4c64-97a2-d64a104b8f7c",
   "metadata": {},
   "source": [
    "# Valid config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1555dea-7508-469d-a64a-b07481a70187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169df95-bdc0-4c68-a282-804db732f23b",
   "metadata": {},
   "source": [
    "# Save the current config\n",
    "\n",
    "In case something goes wrong keep a local state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb06f1-f2a7-43d4-b6b8-e3fe28720d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [k for k in template_config()]\n",
    "df[df.valid][[\"layer_name\", \"folder_name\", \"old_layer_name\"] + keys].sort_values(\"layer_name\").to_csv(\"niva-naming-overview.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5915eb8-81f0-4311-91a0-1498aff635f1",
   "metadata": {},
   "source": [
    "# Replace config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4e5ff-f28a-4e06-be58-c0a2c7f7d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = template_config().keys()\n",
    "for _, data in df[df.valid].iterrows():\n",
    "    tmp_path = Path(\"/home/notebook/seabeepy/notebooks\") / tmp_dir / \"config.seabee.yaml\"\n",
    "    tmp_path.unlink(missing_ok=True)\n",
    "    config = data[keys].to_dict()\n",
    "\n",
    "    # Where possible also allow zero files if they will be uploaded later\n",
    "    sb.ortho.CONFIG_SCHEMA.validate({**config, \"nfiles\": 1})\n",
    "    write_new_config(tmp_dir / \"config.seabee.yaml\", config)\n",
    "    dst_path = os.path.join(data.dir_path, \"config.seabee.yaml\")\n",
    "    print(f\"Updating {data.folder_name}\")\n",
    "    \n",
    "    #sb.storage.copy_file(str(tmp_path), dst_path, minio_client, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a439b-e29f-469f-a87a-e12bb7028ed4",
   "metadata": {},
   "source": [
    "# Delete ortho files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee04e7df-781e-400e-bfd4-d8851c837098",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in df.iterrows():\n",
    "    file_path = data.dir_path / \"orthophoto\" / (data.old_layer_name + \".tif\")\n",
    "    if file_path.exists():\n",
    "        print(f\"Deleting {file_path}\")\n",
    "        sb.storage.delete_file(str(file_path), minio_client)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a11b736-4f47-425e-a105-3490c6c68702",
   "metadata": {},
   "source": [
    "# Delete geonode datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34e887-52fd-450e-8545-c5b818a0c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = sb.geo.GEONODE_URL\n",
    "\n",
    "auth = (SETTINGS.GEONODE_USER, SETTINGS.GEONODE_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584246a-fc97-43e4-a09e-8bb75a7f8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in df.iterrows():\n",
    "    try:\n",
    "        ds = sb.geo.get_dataset_by_title(data.old_layer_name)\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Deleting {data.old_layer_name}\")\n",
    "        r = requests.delete(f\"{base_url}resources/{ds['pk']}\", auth=auth)\n",
    "        print(r.status_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
