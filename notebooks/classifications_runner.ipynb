{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f0d3e-e495-482d-85b3-e03e5b3cfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import seabeepy as sb\n",
    "from seabeepy.config import SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fc337-17b3-45cd-80d5-a39f2be9fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_client = sb.storage.minio_login(\n",
    "    user=SETTINGS.MINIO_ACCESS_ID, password=SETTINGS.MINIO_SECRET_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04508974-d438-4541-b92f-e137bf81489c",
   "metadata": {},
   "source": [
    "# Classify SeaBee orthomosaics (production mode)\n",
    "\n",
    "This notebook uses NR's machine learning workflow to classify orthomosaics from SeaBee missions. It is designed to run as a \"cron job\" that will scan and process all flight folders within the specified `base_dirs`.\n",
    "\n",
    "Orthomosaics for each flight folder must be organised according to the specification [here](https://seabee-no.github.io/documentation/data-upload.html) and already published on the GeoNode.\n",
    "\n",
    "**This workflow focuses on applying existing (i.e. pre-trained) models to new data, not on training new models**. The available pre-trained models are stored in the `models` bucket on MinIO.\n",
    "\n",
    "For the time being, training of new models will be handled by in-house by NR.\n",
    "\n",
    "## 1. User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff0f22-30d0-421d-af2f-29ee8742fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent directories containing flight folders to process\n",
    "base_dirs = [\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2017\",\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2018\",\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2019\",\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2020\",\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2021\",\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2022\",\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2023\",\n",
    "    # r\"/home/notebook/shared-seabee-ns9879k/seabirds/2024\",\n",
    "    r\"/home/notebook/shared-seabee-ns9879k/seabirds/2025\",\n",
    "]\n",
    "\n",
    "# Directory for temporary files\n",
    "temp_dir = r\"/home/notebook/ml_temp/\"\n",
    "\n",
    "# Only publish detections where the confidence score is greater than\n",
    "# or equal to 'det_pub_thresh'\n",
    "det_pub_thresh = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f56848-6ef8-487c-a062-beef1bda1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run info\n",
    "run_date = dt.datetime.today()\n",
    "print(f\"Processing started: {run_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba6af7-8584-466b-ae80-40dfc8c01d38",
   "metadata": {},
   "source": [
    "## 2. Identify missions for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c0e2d-63dd-453c-9044-eb74537e70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all potential folders for classification\n",
    "classify_list = [\n",
    "    f.parent\n",
    "    for base_dir in base_dirs\n",
    "    for f in Path(base_dir).rglob(\"config.seabee.yaml\")\n",
    "    if sb.ortho.parse_config(f.parent)[\"classify\"]\n",
    "    and sb.ml.is_classification_ready(f.parent)\n",
    "    and sb.ortho.check_config_valid(f.parent)\n",
    "    and not sb.ml.check_results_exist(f.parent)\n",
    "]\n",
    "\n",
    "print(\"\\nThe following folders are ready to be processed:\")\n",
    "print(classify_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b0a7a-424a-4169-9075-ec15bf8c60c7",
   "metadata": {},
   "source": [
    "## 3. Run classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a286377f-a5be-4f05-97b8-e5f803804b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for mission_dir in classify_list:\n",
    "    mission_name = sb.ortho.get_layer_name(mission_dir)\n",
    "    print(f\"\\n################\\nProcessing: {mission_name}\")\n",
    "    orthophoto_path = os.path.join(mission_dir, \"orthophoto\", f\"{mission_name}.tif\")\n",
    "    mission_temp_dir = os.path.join(temp_dir, f\"{mission_name}-workdir\")\n",
    "\n",
    "    # Get user settings for ML\n",
    "    ml_options = sb.ml.get_ml_options(mission_dir)\n",
    "    print(f\"Using model '{ml_options['model']}'.\")\n",
    "\n",
    "    # Configure ML pipeline\n",
    "    sb.ml.write_config_production(\n",
    "        orthophoto_path,\n",
    "        mission_temp_dir,\n",
    "        ml_options[\"model\"],\n",
    "        ml_options[\"task\"],\n",
    "    )\n",
    "\n",
    "    # Run classification\n",
    "    try:\n",
    "        sb.ml.run_classification(\n",
    "            mission_name, os.path.join(mission_temp_dir, \"config\"), ml_options[\"task\"]\n",
    "        )\n",
    "\n",
    "        # Copy results to MinIO and clean temp folder\n",
    "        sb.storage.copy_folder(\n",
    "            os.path.join(mission_temp_dir, \"results\"),\n",
    "            str(mission_dir),\n",
    "            minio_client,\n",
    "            overwrite=True,\n",
    "        )\n",
    "        shutil.rmtree(mission_temp_dir)\n",
    "\n",
    "        # # Write detections to PostGIS\n",
    "        # if ml_options[\"task\"] == \"detection\":\n",
    "        #     sb.ml.write_seabird_detections_to_postgis(\n",
    "        #         mission_dir, SETTINGS.DB_USER, SETTINGS.DB_PASSWORD\n",
    "        #     )\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Classification failed for '{mission_name}'.\")\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdaf5f-3a6b-423c-9ab9-37967556e511",
   "metadata": {},
   "source": [
    "## 4. Publish results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758c802-95af-442d-83ed-3fbe156d502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_list = [\n",
    "    f.parent\n",
    "    for base_dir in base_dirs\n",
    "    for f in Path(base_dir).rglob(\"config.seabee.yaml\")\n",
    "    if sb.ortho.parse_config(f.parent)[\"classify\"]\n",
    "    and sb.ortho.check_config_valid(f.parent)\n",
    "    and sb.ml.is_classification_ready(\n",
    "        f.parent\n",
    "    )  # ml.check_results_exist requires published layer\n",
    "    and sb.ml.check_results_exist(f.parent)\n",
    "    and sb.ortho.parse_config(f.parent)[\"publish\"]\n",
    "    and not sb.ml.is_classification_published(f.parent)\n",
    "]\n",
    "\n",
    "print(\"The following missions will be published to GeoNode:\")\n",
    "print(publish_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7886b45-f8f9-4514-a8e5-49364325b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mission_dir in publish_list:\n",
    "    try:\n",
    "        mission_name = sb.ortho.get_layer_name(mission_dir)\n",
    "        print(f\"\\n################\\nProcessing: {mission_name}\")\n",
    "        print(\"Converting class IDs to class names.\")\n",
    "        res_dir = sb.ml.get_latest_results_dir(mission_dir)\n",
    "        res_path = os.path.join(res_dir, \"out.gpkg\")\n",
    "        gdf = gpd.read_file(res_path)\n",
    "\n",
    "        ml_options = sb.ml.get_ml_options(mission_dir)\n",
    "        if ml_options[\"task\"] == \"detection\":\n",
    "            # Seabirds mission\n",
    "            layer_name = f\"{mission_name}_all-detections\"\n",
    "            layer_name_filt = f\"{mission_name}_detections\"\n",
    "            gdf = sb.ml.convert_seabird_class_codes_to_names(\n",
    "                gdf, SETTINGS.DB_USER, SETTINGS.DB_PASSWORD\n",
    "            )\n",
    "            gdf_filt = gdf.query(\"score_species >= @det_pub_thresh\").copy()\n",
    "            style_dict = {\n",
    "                layer_name_filt: f\"red_outline.sld\",\n",
    "            }\n",
    "        else:\n",
    "            # Process segmentation results\n",
    "            # layer_name = f\"{mission_name}_classifications\"\n",
    "            # style_dict = {\n",
    "            #     mission_name: f\"annotation_classes_v{class_version}_level{style_level}.sld\",\n",
    "            # }\n",
    "            pass\n",
    "\n",
    "        print(\"Uploading to GeoServer.\")\n",
    "        # Save locally\n",
    "        temp_gpkg = os.path.join(temp_dir, f\"{layer_name}.gpkg\")\n",
    "        gdf.to_file(temp_gpkg, layer=layer_name)\n",
    "        gdf_filt.to_file(temp_gpkg, layer=layer_name_filt)\n",
    "\n",
    "        # Copy to MinIO and delete local version\n",
    "        gpkg_path = os.path.join(\n",
    "            mission_dir,\n",
    "            \"results\",\n",
    "            ml_options[\"task\"],\n",
    "            ml_options[\"model\"],\n",
    "            f\"{layer_name}.gpkg\",\n",
    "        )\n",
    "        sb.storage.copy_file(temp_gpkg, gpkg_path, minio_client, overwrite=True)\n",
    "        os.remove(temp_gpkg)\n",
    "\n",
    "        # Upload filtered results layer to GeoServer\n",
    "        store_name = sb.geo.upload_geopackage_layers_to_geoserver(\n",
    "            gpkg_path,\n",
    "            [layer_name_filt],\n",
    "            SETTINGS.GEOSERVER_USER,\n",
    "            SETTINGS.GEOSERVER_PASSWORD,\n",
    "            workspace=\"geonode\",\n",
    "            style_dict=style_dict,\n",
    "        )\n",
    "\n",
    "        print(\"Publishing to GeoNode.\")\n",
    "        sb.geo.publish_to_geonode(\n",
    "            layer_name_filt,\n",
    "            SETTINGS.GEONODE_USER,\n",
    "            SETTINGS.GEONODE_PASSWORD,\n",
    "            store_name=store_name,\n",
    "            workspace=\"geonode\",\n",
    "        )\n",
    "\n",
    "        print(\"Updating metadata.\")\n",
    "        metadata = {\n",
    "            \"abstract\": sb.geo.get_detection_abstract(\n",
    "                gdf_filt,\n",
    "                layer_name_filt,\n",
    "                ml_options[\"model\"],\n",
    "                str(gpkg_path),\n",
    "                det_pub_thresh,\n",
    "            ),\n",
    "            \"date\": dt.datetime.strptime(\n",
    "                gdf_filt[\"datetimereg\"].iloc[0], \"%Y-%m-%d %H:%M:%S\"\n",
    "            ).isoformat(),\n",
    "            \"date_type\": \"creation\",\n",
    "            \"attribution\": \"SeaBee\",\n",
    "        }\n",
    "        sb.geo.update_geonode_metadata(\n",
    "            layer_name_filt,\n",
    "            SETTINGS.GEONODE_USER,\n",
    "            SETTINGS.GEONODE_PASSWORD,\n",
    "            metadata,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"**** Error processing {mission_name}:\\n{e}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
