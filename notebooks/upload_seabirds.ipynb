{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c44bc7-58dc-49ca-a0a3-05fcbfffeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from seabeepy.config import SETTINGS\n",
    "from geo.Geoserver import Geoserver\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ca7df-b1ae-4645-80c0-3844230b8e54",
   "metadata": {},
   "source": [
    "# Upload NINA 'seabirds' datasets\n",
    "\n",
    "Processing and uploading NINA's 'seabirds' datasets to GeoNode. The code does the following:\n",
    "\n",
    " * Searches for files named `odm_orthophoto.original.tif` in the `odm_orthophoto` sub-directory for each seabird mission\n",
    " \n",
    " * Discards the `alpha` band, and ensures the remaining bands are converted to 8-bit and saved with internal overviews (i.e. as COGs) using LZW compression (with the `predictor=2` flag enabled)\n",
    " \n",
    " * Adds the processed mosaics to GeoServer\n",
    " \n",
    " * Updates basic metadata\n",
    " \n",
    "## 1. Raster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361e4f9f-832f-4f2d-8342-0952bdebc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"/home/notebook/shared-seabee-ns9879k/seabirds/2022/\"\n",
    "cog_fold = r\"/home/notebook/cogs/\"\n",
    "n_threads = 4\n",
    "n2process = 50  # Number of grids to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316a4318-e93e-4a46-b522-b8ad1c65270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    }
   ],
   "source": [
    "dir_list = sorted(glob(os.path.join(base_dir, \"*/\")))\n",
    "print(len(dir_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32fcd90-2b48-43f7-b2f6-7bfc7fedf0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file size is 10015, 8584\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 17263, 14856\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8928, 12831\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25790, 21508\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 21470, 17668\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25680, 21143\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 27002, 23648\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25142, 26277\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25562, 27416\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25638, 26436\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25874, 26613\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25415, 26682\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 26041, 27642\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25470, 27395\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 25895, 27049\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 24939, 26476\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 20428, 20599\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7373, 8594\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 6803, 6543\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 10112, 7138\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 5861, 4614\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 8901, 14679\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 7954, 5504\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 21884, 14236\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 36329, 34535\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 34665, 26163\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 12428, 8663\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 12183, 48255\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 21665, 22663\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 32799, 34976\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 12591, 21423\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 36319, 35135\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 30724, 33863\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 12660, 12687\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 15951, 16367\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 23814, 26080\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 24541, 26711\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "for dir_path in dir_list[:n2process]:\n",
    "    mission_name = Path(dir_path).name\n",
    "    fpath = os.path.join(dir_path, \"odm_orthophoto\", \"odm_orthophoto.original.tif\")\n",
    "    if os.path.isfile(fpath):\n",
    "        cog_path = os.path.join(cog_fold, mission_name + \".tif\")\n",
    "        cmd = [\n",
    "            \"gdal_translate\",\n",
    "            \"-b\",\n",
    "            \"1\",\n",
    "            \"-b\",\n",
    "            \"2\",\n",
    "            \"-b\",\n",
    "            \"3\",\n",
    "            \"-of\",\n",
    "            \"COG\",\n",
    "            \"-ot\",\n",
    "            \"Byte\",\n",
    "            \"-co\",\n",
    "            \"COMPRESS=LZW\",\n",
    "            \"-co\",\n",
    "            \"PREDICTOR=2\",\n",
    "            \"-co\",\n",
    "            f\"NUM_THREADS={n_threads}\",\n",
    "            \"-co\",\n",
    "            \"OVERVIEWS=IGNORE_EXISTING\",\n",
    "            \"-scale\",\n",
    "            fpath,\n",
    "            cog_path,\n",
    "        ]\n",
    "        subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dba7c1-abe6-4866-bec8-5f6b8067304f",
   "metadata": {},
   "source": [
    "## 2. Upload to GeoServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b173dc35-d746-449e-9cfc-cc16fa8fcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authernticate with GeoServer\n",
    "geo = Geoserver(\n",
    "    \"https://geonode.seabee.sigma2.no/geoserver\",\n",
    "    username=SETTINGS.GEOSERVER_USER,\n",
    "    password=SETTINGS.GEOSERVER_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c1abc4-b853-4297-bc61-02770dcf2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload COGs to GeoServer\n",
    "workspace = \"geonode\"\n",
    "\n",
    "search_path = os.path.join(cog_fold, \"*.tif\")\n",
    "flist = glob(search_path)\n",
    "for fpath in flist:\n",
    "    fname = os.path.basename(fpath)\n",
    "    layer_name = os.path.splitext(fname)[0]\n",
    "\n",
    "    # Add to GeoServer. Note: Will overwrite layer if it exists\n",
    "    status = geo.create_coveragestore(\n",
    "        layer_name=layer_name, path=fpath, workspace=workspace\n",
    "    )\n",
    "    # print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11704b3a-24e9-43b0-a930-65182cc553f6",
   "metadata": {},
   "source": [
    "## 3. Update GeoNode\n",
    "\n",
    "To get the new datasets to appear in GeoNode, login to the GeoNode administration panel and navigate to\n",
    "\n",
    "    Home > Management Commands Over HTTP > Management command jobs\n",
    "    \n",
    "Choose `Add management command job` and set the **Command** to `updatelayers`. Check the **Autostart** box and click **Save**. If you have added a lot of data, the update process may take a while. When it is finished, the status should be updated and the new images datasets be visible in GeoNode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf6ea8f-d775-4ea1-b1e7-ada0c41c51ba",
   "metadata": {},
   "source": [
    "## 4. Update metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2ad40b-0aa3-49cd-b391-8bd9badb92b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929303d411ca497894e592ef6ed9a687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_url = \"https://geonode.seabee.sigma2.no/api/v2/\"\n",
    "\n",
    "auth = (SETTINGS.GEOSERVER_USER, SETTINGS.GEONODE_PASSWORD)\n",
    "\n",
    "search_path = os.path.join(cog_fold, \"*.tif\")\n",
    "flist = glob(search_path)\n",
    "for fpath in tqdm(flist):\n",
    "    fname = os.path.basename(fpath)\n",
    "    layer_name = os.path.splitext(fname)[0]\n",
    "\n",
    "    # Find resource ID\n",
    "    filter_url = base_url + f\"resources?search={layer_name}&search_fields=title\"\n",
    "    response = requests.request(\"GET\", filter_url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    assert data[\"total\"] == 1, f\"More than one dataset found with title '{layer_name}'.\"\n",
    "    dataset_id = data[\"resources\"][0][\"pk\"]\n",
    "\n",
    "    # Extract metadata\n",
    "    area, site, date = layer_name.split(\"_\")\n",
    "    date = dt.datetime.strptime(date, \"%Y%m%d\")\n",
    "    abstract = f\"RGB mosaic collected by NINA (Sindre MolvÃ¦rsmyr) at {site} ({area}) on {date}.\"\n",
    "\n",
    "    # Update metadata\n",
    "    data = {\n",
    "        \"abstract\": abstract,\n",
    "        \"date\": date.isoformat(),\n",
    "        \"date_type\": \"creation\",\n",
    "        \"attribution\": \"SeaBee\",\n",
    "    }\n",
    "    update_url = base_url + f\"datasets/{dataset_id}\"\n",
    "    response = requests.patch(update_url, auth=auth, json=data)\n",
    "    response.raise_for_status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
