{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397a134-8801-4359-9256-3ed92294f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!pip install gref4hsi==0.2.5\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Uncomment this block if developing on the gref4hsi\n",
    "\"\"\"\n",
    "!pip uninstall gref4hsi\n",
    "home_path = \"/home/fc-3auid-3af522edce-2ddb4d-2d4b8c-2d8500-2df5376270c3e0\"\n",
    "module_path = os.path.join(home_path, \"gitprojects/gref4hsi\")  # Replace with the actual path\n",
    "sys.path.append(module_path)\n",
    "import gref4hsi # Ensure that module is installed correctly, will throw error otherwize\n",
    "\"\"\"\n",
    "# Install py6s using conda (assuming mamba is a conda alias)\n",
    "try:\n",
    "    import Py6S\n",
    "except ImportError:\n",
    "    !mamba install -y py6s\n",
    "\n",
    "!pip install rad4sea==0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fed5a7-ef9c-4eef-81fd-80a029192e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af93a87-9797-40fe-8a5f-b32002207169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python library\n",
    "import argparse\n",
    "import configparser\n",
    "import os\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "\n",
    "# Third party\n",
    "import numpy as np\n",
    "\n",
    "# Local resources\n",
    "from gref4hsi.scripts import coregistration, georeference, orthorectification\n",
    "from gref4hsi.utils import parsing_utils, specim_parsing_utils, visualize\n",
    "from gref4hsi.utils.config_utils import (\n",
    "    customize_config,\n",
    "    prepend_data_dir_to_relative_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb1fea-0c10-4e2a-9431-22b74b638ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From seabeepy/notebooks/flight_runner\n",
    "import datetime as dt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from subprocess import CalledProcessError\n",
    "\n",
    "import rad4sea\n",
    "from pyodm import Node\n",
    "\n",
    "import seabeepy as sb\n",
    "from seabeepy.config import SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f66eef-7fbd-4efd-9cbe-91007d1c6917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Login to MinIO\n",
    "minio_client = sb.storage.minio_login(\n",
    "    user=SETTINGS.MINIO_ACCESS_ID, password=SETTINGS.MINIO_SECRET_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9281e-4706-4e06-b944-dfd7c783d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent directories containing flight folders to process\n",
    "base_dirs = [\n",
    "    r\"/home/notebook/shared-seabee-ns9879k/ntnu\",\n",
    "]\n",
    "\n",
    "# Directory for temporary files\n",
    "temp_dir = r\"/home/notebook/cogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c7d5b-d8f8-429b-9cd8-afd9f46b8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run info\n",
    "run_date = dt.datetime.today()\n",
    "print(f\"Processing started: {run_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca6de5-e204-43fd-998c-53a8e68876f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all potential mission folders for NodeODM\n",
    "# (i.e. folders containing a 'config.seabee.yaml' and an 'capture' subdirectory, but NOT a 'processed' directory)\n",
    "mission_list = [\n",
    "    f.parent\n",
    "    for base_dir in base_dirs\n",
    "    for f in Path(base_dir).rglob(\"config.seabee.yaml\")\n",
    "    if sb.ortho.check_subdir_exists(f.parent, \"capture\")\n",
    "    and not sb.ortho.check_subdir_exists(f.parent, \"processed\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cbf91-d613-4f3d-9c2a-ab404424f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec010b3-a209-4291-b465-cb4f295b6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the ancillary data paths, copy to local work space and\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "geoid_path_minio = Path(\n",
    "    \"/home/notebook/shared-seabee-ns9879k/ntnu/specim_processing_data/geoids/no_kv_HREF2018A_NN2000_EUREF89.tif\"\n",
    ")\n",
    "config_template_path_minio = Path(\n",
    "    \"/home/notebook/shared-seabee-ns9879k/ntnu/specim_processing_data/configuration_specim.ini\"\n",
    ")\n",
    "lab_calibration_path_minio = Path(\n",
    "    \"/home/notebook/shared-seabee-ns9879k/ntnu/specim_processing_data/Lab_Calibrations\"\n",
    ")\n",
    "\n",
    "# Local path geoid\n",
    "geoid_path = os.path.join(temp_dir, \"no_kv_HREF2018A_NN2000_EUREF89.tif\")\n",
    "try:\n",
    "    shutil.copyfile(geoid_path_minio, geoid_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Local path for configuration file\n",
    "config_template_path = os.path.join(temp_dir, \"config_template_path_specim.ini\")\n",
    "try:\n",
    "    shutil.copyfile(config_template_path_minio, config_template_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Local path for lab calibration\n",
    "lab_calibration_path = os.path.join(temp_dir, \"lab-calibration\")\n",
    "try:\n",
    "    shutil.copytree(lab_calibration_path_minio, lab_calibration_path)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cf748-2313-49e9-b535-9f1b56abc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Convenient for development, effectively avoiding kernel restart\n",
    "import importlib\n",
    "import shutil\n",
    "\n",
    "import process_hyperspectral\n",
    "\n",
    "importlib.reload(process_hyperspectral)\n",
    "\n",
    "# Process missions in the list\n",
    "for specim_mission_folder_minio in mission_list:\n",
    "\n",
    "    mission_name = specim_mission_folder_minio.name\n",
    "    print(f\"\\n################\\nProcessing: {mission_name}\")\n",
    "\n",
    "    specim_mission_folder = os.path.join(temp_dir, specim_mission_folder_minio.name)\n",
    "\n",
    "    # Copy to local fs if not there already\n",
    "    try:\n",
    "        print(\"Copying file\")\n",
    "        shutil.copytree(specim_mission_folder_minio, specim_mission_folder)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # The config file is read\n",
    "    config_yaml = os.path.join(specim_mission_folder, \"config.seabee.yaml\")\n",
    "\n",
    "    # Specim processing to get georeferenced radiance data\n",
    "    # Setting fast_mode to true can be smart for development purposes as it creates a coarse image\n",
    "    process_hyperspectral.main(\n",
    "        str(config_yaml),\n",
    "        str(specim_mission_folder),\n",
    "        geoid_path,\n",
    "        config_template_path,\n",
    "        lab_calibration_path,\n",
    "        fast_mode=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a109a-5452-453d-88c0-ff978ac77039",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Convert radiance data into reflectance by division with simulated spectrum from Py6S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22e880-f2f0-43f1-be4c-7a571636004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raster and ancillary (\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import rasterio\n",
    "import spectral as sp\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Uncomment if you are doing module development\n",
    "\"\"\"\n",
    "module_path = os.path.join('/home/notebook/', 'gitprojects/rad4sea/')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\"\"\"\n",
    "\n",
    "import importlib\n",
    "\n",
    "import rad2refl\n",
    "import rad4sea\n",
    "\n",
    "importlib.reload(rad4sea)\n",
    "importlib.reload(rad2refl)\n",
    "\n",
    "# The radiance multiplier for the specim afx10 relative to unit of W/(m^2*sr*nm)\n",
    "radiance_multiplier_specim = 1 / 1000  # (mW/cm^2*sr*um)*1000.0000 ->(mW/cm^2*sr*um)\n",
    "radiance_multiplier_specim *= 1e-3 / 1e-4  # (mW/cm^2*sr*um) -> (W/m^2*sr*um)\n",
    "radiance_multiplier_specim *= 1 / 1e3  # (W/m^2*sr*um) -> (W/m^2*sr*nm)\n",
    "\n",
    "\n",
    "for specim_mission_folder_minio in mission_list:\n",
    "\n",
    "    # Select a particular transect datacube:\n",
    "    specim_mission_folder = os.path.join(temp_dir, specim_mission_folder_minio.name)\n",
    "\n",
    "    print(specim_mission_folder)\n",
    "\n",
    "    # Where the cube and anc data are\n",
    "\n",
    "    if os.path.exists(os.path.join(specim_mission_folder, \"processed/Output/GIS/\")):\n",
    "        cube_folder = os.path.join(\n",
    "            specim_mission_folder, \"processed/Output/GIS/HSIDatacubes/\"\n",
    "        )\n",
    "        anc_folder = os.path.join(\n",
    "            specim_mission_folder, \"processed/Output/GIS/AncillaryData/\"\n",
    "        )\n",
    "    else:\n",
    "        # If already processed and reflectance processing is to be conducted with overwriting\n",
    "        cube_folder = os.path.join(specim_mission_folder, \"processed/cubes\")\n",
    "        anc_folder = os.path.join(specim_mission_folder, \"processed/ancillary\")\n",
    "\n",
    "    # Make copies of radiance data for manipulation\n",
    "    for filename in os.listdir(cube_folder):\n",
    "        if filename.lower().endswith(\".img\") or filename.lower().endswith(\n",
    "            \".hdr\"\n",
    "        ):  # Check for lowercase extension\n",
    "            base, ext = os.path.splitext(filename)  # Separate base name and extension\n",
    "\n",
    "            if base.split(\"_\")[-1] == \"reflectance\":\n",
    "                pass\n",
    "            else:\n",
    "                new_filename = (\n",
    "                    f\"{base}_reflectance{ext}\"  # Construct new filename with suffix\n",
    "                )\n",
    "                source_file = os.path.join(cube_folder, filename)\n",
    "                destination_file = os.path.join(cube_folder, new_filename)\n",
    "                # Copy the file\n",
    "\n",
    "                shutil.copyfile(source_file, destination_file)\n",
    "\n",
    "    # We only modulate the copy of the data (with _reflectance suffix)\n",
    "    cube_hdr_list = glob.glob(cube_folder + \"/*_reflectance.hdr\")\n",
    "\n",
    "    # Simulates downwelling irradiance and computes remote sensing reflectance\n",
    "    rad2refl.main(\n",
    "        anc_folder=anc_folder,\n",
    "        cube_list_refl=cube_hdr_list,\n",
    "        cube_folder=cube_folder,\n",
    "        radiance_multiplier=radiance_multiplier_specim,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43a47a-6db1-4deb-b8ab-70343b98636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b94b1-6a05-4316-afd4-b8a9692b61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A simple demonstration of the data for a transect showing radiance, reflectance and an RGB composite\"\"\"\n",
    "\n",
    "# Try to visualize\n",
    "try:\n",
    "    specim_mission_folder_minio = mission_list[0]\n",
    "    specim_mission_folder = os.path.join(temp_dir, specim_mission_folder_minio.name)\n",
    "    cube_folder = os.path.join(\n",
    "        specim_mission_folder, \"processed/Output/GIS/HSIDatacubes/\"\n",
    "    )\n",
    "    anc_folder = os.path.join(\n",
    "        specim_mission_folder, \"processed/Output/GIS/AncillaryData/\"\n",
    "    )\n",
    "\n",
    "    cube_hdr_list = glob.glob(cube_folder + \"/*_reflectance.hdr\")\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Example plotting of radiance data\n",
    "    refl_image_obj = sp.io.envi.open(cube_hdr_list[0])\n",
    "\n",
    "    band_im_refl = refl_image_obj[:, :, 100]\n",
    "    nodata = float(refl_image_obj.metadata[\"data ignore value\"])\n",
    "    wl = np.array(refl_image_obj.metadata[\"wavelengths\"]).astype(np.float64)\n",
    "\n",
    "    valids = (band_im_refl != nodata).squeeze()\n",
    "\n",
    "    n_rows, n_cols, _ = band_im_refl.shape\n",
    "\n",
    "    row_indices = np.repeat(np.arange(n_rows).reshape((-1, 1)), n_cols, axis=1)\n",
    "    col_indices = np.repeat(np.arange(n_cols).reshape((1, -1)), n_rows, axis=0)\n",
    "    # print(row_indices.shape)\n",
    "    row_valids = row_indices[valids]\n",
    "    col_valids = col_indices[valids]\n",
    "\n",
    "    n_valids = row_valids.size\n",
    "    spec_idx_example = int(\n",
    "        n_valids / 2\n",
    "    )  # Some random spectrum in the image. Index can be from 0 to n_valids\n",
    "\n",
    "    print(cube_hdr_list[0])\n",
    "    plt.plot(\n",
    "        wl,\n",
    "        refl_image_obj[\n",
    "            row_valids[spec_idx_example], col_valids[spec_idx_example], :\n",
    "        ].flatten(),\n",
    "    )\n",
    "    plt.ylabel(\"Remote sensing reflectance [1/sr]\")\n",
    "    plt.xlabel(\"Nanometers [nm]\")\n",
    "    plt.show()\n",
    "\n",
    "    rad_image_obj = sp.io.envi.open(\n",
    "        \"_\".join(cube_hdr_list[0].split(\"_\")[0:-1]) + \".hdr\"\n",
    "    )\n",
    "    rad_specim_example = rad_image_obj[\n",
    "        row_valids[spec_idx_example], col_valids[spec_idx_example], :\n",
    "    ].flatten()\n",
    "    plt.plot(wl, rad_specim_example * radiance_multiplier_specim)\n",
    "    plt.ylabel(\"Radiance [mW/(m$^2$ sr nm)]\")\n",
    "    plt.xlabel(\"Nanometers [nm]\")\n",
    "    plt.show()\n",
    "\n",
    "    pad = 10\n",
    "    rows_zoom = np.arange(\n",
    "        row_valids[spec_idx_example] - pad, row_valids[spec_idx_example] + pad\n",
    "    )\n",
    "    cols_zoom = np.arange(\n",
    "        col_valids[spec_idx_example] - pad, col_valids[spec_idx_example] + pad\n",
    "    )\n",
    "\n",
    "    RGB = refl_image_obj[:, :, [73, 50, 24]]\n",
    "\n",
    "    RGB.shape\n",
    "\n",
    "    # Emulates a gamma stretch to bring out contrast in dark areas\n",
    "    plt.imshow((RGB / RGB.max()) ** 0.44, vmin=0)\n",
    "    plt.scatter(\n",
    "        row_valids[spec_idx_example],\n",
    "        col_valids[spec_idx_example],\n",
    "        label=\"Sample spectrum\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eae8f9-87d4-4185-b1e9-64cd87a89707",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Transfer to MinIO and Publish to GeoNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7fccb-dea0-4778-ae69-6efecb59c3e0",
   "metadata": {},
   "source": [
    "### 4.1 Convert RGB composites into one one mosaic (no fancy stretching or similar yet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4952d782-3412-4121-83c5-91cca53e9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def merge_rasters(raster_file_list, output_file):\n",
    "    \"\"\"Merges the geotif files in a directory into one geoTIF\"\"\"\n",
    "    ds_lst = list()\n",
    "    for raster in raster_file_list:\n",
    "        ds = gdal.Warp(\"\", raster, format=\"vrt\")\n",
    "        ds_lst.append(ds)\n",
    "    dataset = gdal.BuildVRT(\"\", ds_lst)\n",
    "    ds1 = gdal.Translate(output_file, dataset)\n",
    "    del ds1\n",
    "    del dataset\n",
    "    # Add band info if not there yet\n",
    "    with rio.open(output_file, \"r+\") as src:\n",
    "        if any(val is None for val in src.descriptions):\n",
    "            src.descriptions = (\"red\", \"green\", \"blue\")\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d885c-f1a4-4d63-98a4-eb177b519ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def gamma_transform(data, gamma=0.44, min_prc=2, max_prc=98):\n",
    "    \"\"\"Applies gamma transformation to data.\n",
    "\n",
    "    Args:\n",
    "        data: Input 3 band radiance data.\n",
    "        gamma: Gamma value for the transformation.\n",
    "\n",
    "    Returns:\n",
    "        Gamma-transformed 8-bit data array.\n",
    "    \"\"\"\n",
    "\n",
    "    data_min_prc = np.percentile(data, min_prc)\n",
    "\n",
    "    data_max_prc = np.percentile(data, max_prc)\n",
    "\n",
    "    norm_data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "    # Mapping that enhances dark areas if gamma < 1\n",
    "    gamma_data = (norm_data**gamma) * 255\n",
    "\n",
    "    # Stretch data in case there are some very bright areas in image\n",
    "\n",
    "    data_min_prc = np.percentile(gamma_data, min_prc)\n",
    "\n",
    "    data_max_prc = np.percentile(gamma_data, max_prc)\n",
    "\n",
    "    undersaturated = gamma_data <= data_min_prc\n",
    "    oversaturated = gamma_data >= data_max_prc\n",
    "\n",
    "    # Rest of data is stretched\n",
    "    gamma_data = np.ceil(\n",
    "        ((gamma_data - data_min_prc) / (data_max_prc - data_min_prc)) * 255\n",
    "    )\n",
    "\n",
    "    gamma_data[undersaturated] = 1\n",
    "    gamma_data[oversaturated] = 255\n",
    "\n",
    "    # Cast to 8 bit\n",
    "    gamma_data = gamma_data.astype(np.uint8)\n",
    "\n",
    "    return gamma_data\n",
    "\n",
    "\n",
    "def apply_gamma_transform(raster_file, gamma):\n",
    "    \"\"\"Transforms the RGB raster to enhance color\"\"\"\n",
    "    with rio.open(raster_file, \"r+\") as src:\n",
    "        profile = src.profile\n",
    "        count = src.count\n",
    "\n",
    "        # Update profile for 8-bit unsigned integer data type\n",
    "        kwargs = profile\n",
    "        kwargs.update(dtype=rasterio.uint8, nodata=0)\n",
    "\n",
    "        # Create a new dataset for writing\n",
    "        with rasterio.open(raster_file, \"w\", **kwargs) as dst:\n",
    "            for i in range(1, count + 1):\n",
    "                # Read the band data\n",
    "                band_data = src.read(i)\n",
    "\n",
    "                gamma_data = np.zeros(band_data.shape, dtype=np.uint8)\n",
    "\n",
    "                # Where the data is\n",
    "                data_mask = band_data != src.nodata\n",
    "\n",
    "                # Apply gamma transformation\n",
    "                gamma_data[data_mask] = gamma_transform(band_data[data_mask], gamma)\n",
    "\n",
    "                print(dst.nodata)\n",
    "\n",
    "                # Write the gamma-transformed data back to the band\n",
    "                dst.write(gamma_data, i)\n",
    "\n",
    "            if any(val is None for val in dst.descriptions):\n",
    "                dst.descriptions = (\"red\", \"green\", \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1733439f-cd01-4111-913c-8cab4da5c873",
   "metadata": {},
   "source": [
    "### 4.2 Copy processed data to specim_mission_folder_minio/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e28ba4-940b-45e8-ab02-a0d116b332dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import rasterio\n",
    "\n",
    "for specim_mission_folder_minio in mission_list:\n",
    "    # Select a particular transect datacube:\n",
    "    specim_mission_folder = os.path.join(temp_dir, specim_mission_folder_minio.name)\n",
    "\n",
    "    # Where the cube and anc data are\n",
    "    # cube_folder = os.path.join(specim_mission_folder, \"processed/Output/GIS/HSIDatacubes/\")\n",
    "    # anc_folder = os.path.join(specim_mission_folder, \"processed/Output/GIS/AncillaryData/\")\n",
    "\n",
    "    # Processed Cubes MINIO\n",
    "    cubes_path_minio = os.path.join(specim_mission_folder_minio, \"processed/cubes\")\n",
    "\n",
    "    # Processed ancillary cubes MINIO\n",
    "    anc_cube_path_minio = os.path.join(\n",
    "        specim_mission_folder_minio, \"processed/ancillary\"\n",
    "    )\n",
    "\n",
    "    # Processed composites MINIO are now stored under composites_path\n",
    "    # And should be moved to\n",
    "    composites_path_minio = os.path.join(\n",
    "        specim_mission_folder_minio, \"processed/composites\"\n",
    "    )\n",
    "\n",
    "    # Where is the processed data\n",
    "    cube_folder = os.path.join(\n",
    "        specim_mission_folder, \"processed/Output/GIS/HSIDatacubes/\"\n",
    "    )\n",
    "    anc_folder = os.path.join(\n",
    "        specim_mission_folder, \"processed/Output/GIS/AncillaryData/\"\n",
    "    )\n",
    "    composites_path = os.path.join(\n",
    "        specim_mission_folder, \"processed/Output/GIS/RGBComposites\"\n",
    "    )\n",
    "\n",
    "    # Processed composites are now stored under\n",
    "\n",
    "    # And should be moved to\n",
    "    composites_path_minio = os.path.join(\n",
    "        specim_mission_folder_minio, \"processed/composites\"\n",
    "    )\n",
    "\n",
    "    composite_list = glob.glob(composites_path + \"/*.tif\")\n",
    "\n",
    "    # The combined version is to be deployed on GEONODE\n",
    "    combined_composite_filename = os.path.join(composites_path, \"combined.tif\")\n",
    "\n",
    "    merge_rasters(composite_list, combined_composite_filename)\n",
    "\n",
    "    apply_gamma_transform(combined_composite_filename, gamma=0.44)\n",
    "\n",
    "    # Then we transfer the results to MinIO\n",
    "    # Processed datacubes are now stored under\n",
    "    cubes_path = cube_folder\n",
    "    cubes_path_minio = os.path.join(specim_mission_folder_minio, \"processed/cubes\")\n",
    "\n",
    "    # Processed ancillary cubes are now stored under\n",
    "    anc_cube_path = anc_folder\n",
    "    anc_cube_path_minio = os.path.join(\n",
    "        specim_mission_folder_minio, \"processed/ancillary\"\n",
    "    )\n",
    "\n",
    "    # Processed composites are now stored under composites_path\n",
    "    # And should be moved to\n",
    "    composites_path_minio = os.path.join(\n",
    "        specim_mission_folder_minio, \"processed/composites\"\n",
    "    )\n",
    "\n",
    "    # Move datacube, composites and ancillary data to persistant storage on Minio\n",
    "    # Cubes (radiance and reflectance)\n",
    "\n",
    "    try:\n",
    "        sb.storage.copy_folder(\n",
    "            src_fold=cubes_path,\n",
    "            dst_fold=cubes_path_minio,\n",
    "            client=minio_client,\n",
    "            containing_folder=False,\n",
    "            overwrite=False,\n",
    "        )\n",
    "\n",
    "        # Composite data (One per transect and a combined for visualization)\n",
    "        sb.storage.copy_folder(\n",
    "            src_fold=composites_path,\n",
    "            dst_fold=composites_path_minio,\n",
    "            client=minio_client,\n",
    "            containing_folder=False,\n",
    "            overwrite=False,\n",
    "        )\n",
    "        # sb.storage.copy_file(combined_composite_filename, os.path.join(composites_path_minio,'combined.tif'), client = minio_client, overwrite = True)\n",
    "\n",
    "        # Ancillary data for further processing\n",
    "        sb.storage.copy_folder(\n",
    "            src_fold=anc_cube_path,\n",
    "            dst_fold=anc_cube_path_minio,\n",
    "            client=minio_client,\n",
    "            containing_folder=False,\n",
    "            overwrite=False,\n",
    "        )\n",
    "    except:\n",
    "        processed_path = os.path.join(specim_mission_folder_minio, \"processed\")\n",
    "        print(f\"The folder {processed_path} already exists, no copying is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108bd89-3d28-4037-9c1f-3c4a34d342b1",
   "metadata": {},
   "source": [
    "### 4.3 Publish data to Geonode/Geoserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc404e8-73e8-4add-a9cd-de561912b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify datasets for publishing. Folders must contain either an ODM or Pix4D\n",
    "# original orthophoto (not both) and must not contain a COG named f'{layer_name}.tif'.\n",
    "# Folders must also have 'config.seabee.yaml' files where 'publish' is True\n",
    "publish_list = [\n",
    "    f.parent\n",
    "    for base_dir in base_dirs\n",
    "    for f in Path(base_dir).rglob(\"config.seabee.yaml\")\n",
    "    if sb.ortho.check_subdir_exists(f.parent, \"capture\")\n",
    "    and sb.ortho.check_subdir_exists(f.parent, \"processed\")\n",
    "    and not sb.ortho.check_subdir_exists(f.parent, \"orthophoto\")\n",
    "    and sb.ortho.parse_config(f.parent)[\"publish\"]\n",
    "]\n",
    "\n",
    "print(\"The following missions are publishable to GeoNode:\")\n",
    "print(publish_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109dd30-b52f-41e6-b955-420d61b2424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import rasterio as rio\n",
    "import yaml\n",
    "\n",
    "# Publish publishables (equivalent to the same section in flights_runner.ipynb without the ODM/Pix4D stuff which does not apply here)\n",
    "for mission_fold in publish_list:\n",
    "    mission_name = mission_fold.name\n",
    "\n",
    "    # Orthophoto is termed \"combined.tif\"\n",
    "    ortho_path = os.path.join(mission_fold, \"processed/composites\", \"combined.tif\")\n",
    "\n",
    "    config_yaml_minio = os.path.join(mission_fold, \"config.seabee.yaml\")\n",
    "\n",
    "    specim_mission_folder = os.path.join(temp_dir, mission_name)\n",
    "\n",
    "    try:\n",
    "        h5_dir = os.path.join(specim_mission_folder, \"processed/Input/H5\")\n",
    "        nfiles = len(os.listdir(h5_dir))\n",
    "    except:\n",
    "\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n################\\nProcessing: {mission_name}\")\n",
    "    print(\"Preparing orthophoto for publishing.\")\n",
    "\n",
    "    print(nfiles)\n",
    "\n",
    "    # Prior to updating metadata we need to set the \"nfiles\" entry in config.seabee.yaml\n",
    "\n",
    "    config_yaml = os.path.join(specim_mission_folder, \"config.seabee.yaml\")\n",
    "\n",
    "    # Add entry nfiles\n",
    "    with open(config_yaml, \"r+\") as file:\n",
    "        config_data = yaml.safe_load(file)\n",
    "        config_data[\"nfiles\"] = nfiles\n",
    "        config_data[\"organisation\"] = \"NTNU\"\n",
    "\n",
    "        # After modifying the data, write it back to the file\n",
    "        yaml.safe_dump(config_data, file)\n",
    "\n",
    "    with open(config_yaml, \"r\") as file:\n",
    "        config_data = yaml.safe_load(file)\n",
    "        print(config_data[\"nfiles\"])\n",
    "        print(config_data[\"creator_name\"])\n",
    "\n",
    "    # Overwrite minio config version\n",
    "    sb.storage.copy_file(\n",
    "        config_yaml, config_yaml_minio, client=minio_client, overwrite=True\n",
    "    )\n",
    "\n",
    "    # Standardise and save locally\n",
    "    layer_name = sb.ortho.get_layer_name(mission_fold)\n",
    "    temp_path = os.path.join(temp_dir, layer_name + \".tif\")\n",
    "\n",
    "    try:\n",
    "        sb.geo.standardise_orthophoto(ortho_path, temp_path)\n",
    "    except CalledProcessError as e:\n",
    "        print(f\"Failed to standardise {ortho_path}.\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    # Copy to MinIO and delete local version\n",
    "    stan_path = os.path.join(mission_fold, \"orthophoto\", layer_name + \".tif\")\n",
    "    sb.storage.copy_file(temp_path, stan_path, minio_client, overwrite=True)\n",
    "    os.remove(temp_path)\n",
    "\n",
    "    print(\"Uploading to GeoServer.\")\n",
    "\n",
    "    sb.geo.upload_raster_to_geoserver(\n",
    "        stan_path,\n",
    "        SETTINGS.GEOSERVER_USER,\n",
    "        SETTINGS.GEOSERVER_PASSWORD,\n",
    "        workspace=\"geonode\",\n",
    "    )\n",
    "\n",
    "    print(\"Publishing to GeoNode.\")\n",
    "\n",
    "    sb.geo.publish_to_geonode(\n",
    "        layer_name,\n",
    "        SETTINGS.GEONODE_USER,\n",
    "        SETTINGS.GEONODE_PASSWORD,\n",
    "        workspace=\"geonode\",\n",
    "    )\n",
    "\n",
    "    print(\"Updating metadata.\")\n",
    "    date = sb.ortho.parse_mission_data(mission_fold, parse_date=True)[2]\n",
    "    abstract = sb.geo.get_html_abstract(str(mission_fold))\n",
    "    metadata = {\n",
    "        \"abstract\": abstract,\n",
    "        \"date\": date.isoformat(),\n",
    "        \"date_type\": \"creation\",\n",
    "        \"attribution\": \"SeaBee\",\n",
    "    }\n",
    "    sb.geo.update_geonode_metadata(\n",
    "        layer_name,\n",
    "        SETTINGS.GEONODE_USER,\n",
    "        SETTINGS.GEONODE_PASSWORD,\n",
    "        metadata,\n",
    "    )\n",
    "    print(layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9630ab4-c193-4448-be0b-5f6ee2f9d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.geo.infer_geotiff_metadata(ortho_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de693c25-43e0-46b3-b69e-1dcb9ae04f65",
   "metadata": {},
   "source": [
    "### 4.4 Delete local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dadee52-52cc-4fc9-9f29-316c7b4afd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Delete the local data. This should only be done once everything is well in place\"\"\"\n",
    "\n",
    "for specim_mission_folder_minio in mission_list:\n",
    "    specim_mission_folder = os.path.join(temp_dir, specim_mission_folder_minio.name)\n",
    "    shutil.rmtree(specim_mission_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d424f08-2622-4409-bbfa-859600c5752c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f553ed9-df96-41cd-9502-3c2e8a4080cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
